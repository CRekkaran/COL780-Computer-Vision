{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():  \n",
    "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "    print('Supressed Warnings..')\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "FAST_RUN = True\n",
    "IMAGE_WIDTH=50\n",
    "IMAGE_HEIGHT=50\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(\"./canny/train\")\n",
    "categories = []\n",
    "for filename in filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    if category == 'next':\n",
    "        categories.append(1)\n",
    "    elif category == 'prev':\n",
    "        categories.append(2)\n",
    "    elif category == 'pause':\n",
    "        categories.append(3)\n",
    "    elif category == 'others':\n",
    "        categories.append(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'category': categories\n",
    "})\n",
    "print(df.head(20))\n",
    "df.tail()\n",
    "df['category'].value_counts().plot.bar()\n",
    "sample = random.choice(filenames)\n",
    "image = load_img(\"./canny/train/\"+sample)\n",
    "plt.imshow(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model = Sequential()\n",
    "# ----------------PHASE 0\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(2, activation='softmax')) # 2 because we have cat and dog classes\n",
    "\n",
    "#-----PHASE 1\n",
    "model.add(Conv2D(32, (2, 2), input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS))) \n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "  \n",
    "model.add(Conv2D(32, (2, 2))) \n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "  \n",
    "model.add(Conv2D(64, (2, 2))) \n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "  \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(64)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(4)) \n",
    "model.add(Activation('sigmoid')) \n",
    "\n",
    "#-------PHASE 2\n",
    "# model.add(Conv2D(6, (3, 3), input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS))) \n",
    "# model.add(Activation('relu')) \n",
    "# model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "  \n",
    "# model.add(Conv2D(32, (2, 2))) \n",
    "# model.add(Activation('relu')) \n",
    "# model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "  \n",
    "# model.add(Conv2D(64, (2, 2))) \n",
    "# model.add(Activation('relu')) \n",
    "# model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "  \n",
    "# model.add(Flatten()) \n",
    "# model.add(Dense(64)) \n",
    "# model.add(Activation('relu')) \n",
    "# model.add(Dropout(0.5)) \n",
    "# model.add(Dense(4)) \n",
    "# model.add(Activation('sigmoid')) \n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "# model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystop = EarlyStopping(patience=5)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.0001)\n",
    "\n",
    "callbacks = [earlystop, learning_rate_reduction]\n",
    "df[\"category\"] = df[\"category\"].replace({3: 'pause', 1: 'next', 2: 'prev', 4: 'others'})\n",
    "\n",
    "\n",
    "# 2 - cross validation\n",
    "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "\n",
    "train_df['category'].value_counts().plot.bar()\n",
    "validate_df['category'].value_counts().plot.bar()\n",
    "total_train = train_df.shape[0]\n",
    "total_validate = validate_df.shape[0]\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def prepro(img):\n",
    "    gray_image = cv2.cvtColor(np.float32(img), cv2.COLOR_BGR2GRAY)\n",
    "    print(gray_image.shape)\n",
    "    return gray_image\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "#     vertical_flip=True,\n",
    "#     preprocessing_function=prepro,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, \n",
    "    \"./canny/train/\", \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    \"./canny/train/\", \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ") \n",
    "\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# for i in range(0, 15):\n",
    "#     plt.subplot(5, 3, i+1)\n",
    "#     for X_batch, Y_batch in example_generator:\n",
    "#         image = X_batch[0]\n",
    "#         plt.imshow(image)\n",
    "#         break\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10 if FAST_RUN else 10\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize training\n",
    "# fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "# ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "# ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "# ax1.set_xticks(np.arange(1, epochs, 1))\n",
    "# ax1.set_yticks(np.arange(0, 1, 0.1))\n",
    "\n",
    "# ax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "# ax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "# ax2.set_xticks(np.arange(1, epochs, 1))\n",
    "\n",
    "# legend = plt.legend(loc='best', shadow=True)\n",
    "# plt.tight_layout()\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = os.listdir('./canny/test1')\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': test_filenames\n",
    "})\n",
    "nb_samples = test_df.shape[0]\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_gen.flow_from_dataframe(\n",
    "    test_df, \n",
    "    \"./canny/test1/\", \n",
    "    x_col='filename',\n",
    "    y_col=None,\n",
    "    class_mode=None,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))\n",
    "print(test_df.shape)\n",
    "print(predict.shape)\n",
    "test_df['category'] = np.argmax(predict, axis=-1)\n",
    "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n",
    "test_df['category'] = test_df['category'].replace(label_map)\n",
    "# test_df['category'] = test_df['category'].replace({ 'next': 1, 'pause': 0 })\n",
    "test_df['category'].value_counts().plot.bar()\n",
    "\n",
    "sample_test = test_df.tail(18)\n",
    "print('------------------Testing Data---------------------')\n",
    "print(sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model_in_json.json\", \"w\") as json_file:\n",
    "    json.dump(model_json, json_file)\n",
    "\n",
    "model.save_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict[1])\n",
    "# print(test_df.at(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
